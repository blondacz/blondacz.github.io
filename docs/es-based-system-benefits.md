# Plasma Reactor / Plasma ES

>__**-**__ Actor-Based Event-Sourcing System with CQRS, Transactionality, and High Availability

This document describes an **actor-based event-sourcing system**, that utilizes **CQRS** concepts, ensures **exactly-once** processing, and provides **high availability** through replication. 
Each domain entity is modeled as an actor, which processes commands, generates events.

---

## 1. Command Handling and Transactionality

1. **Actor Model and Domain Entities**  
   Each entity (e.g., Obligation, Instruction, WorkItem) is represented by its own actor. A command such as `Settle` or `Confirm` is routed to the appropriate actor or set of actors.
   External commands are not always imperatives as they are usually events, and therefore verbs, generated by the upstream system. Changing the names in the deserialization layer is minimized to avoid extra mental translation.

2. **Depth-First Traversal**  
   A single command can result in updates to one or many actors. Each actor may generate zero or more events to update its own state, and can also send further commands to other actors within the same transaction flow. 
   This traversal happens in a depth-first manner until all required updates are completed.

3. **All-or-Nothing Event Persistence**  
   Once the entire command flow and actor traversal finish successfully, all generated events are committed together. If any part fails, no events are persisted. This ensures a strict transactional boundary: either all changes from a command succeed, or none do.
   At this point two other processes are executed as systems keeps track of all updates actors during traversal:
   - snapshotting if the actors are registered for it and snapshottable based on their state and metadata
   - caching - actors are removed or added to the actor cache (process which is driven by actor type, actor state, cache configuration and memory available)
   - there is potential to do also secondary indexing at this point, but has not been done yet

---

## 2. Event-Sourcing with Exactly-Once Guarantees

1. **Event Generation**  
   Actors record every state change in the form of domain events (e.g., `OrderPlaced`, `InventoryDecremented`). These events provide an immutable, auditable history of all state transitions.

2. **Immutability and Recovery**  
   Because events are immutable and stored in sequence, an actor can fully recover its state by replaying all events that belong to it. We call this process re-hydration 

3. **Ensuring Exactly-Once Processing**  
   Transactionality and careful in-memory bookkeeping prevent the same event from being applied more than once. By committing events only after the entire command flow succeeds (and discarding them otherwise), the system guarantees that each event is processed exactly once and system does not store partial results.
   That allows restarting from the given external command if necessary (i.e. after fixing application code , that did not anticipate the event or specific data within the event/command)

---

## 3. Replication and Persistence Flow

1. **Replication Before Persistence**  
   Events generated by a successful transaction are first replicated to a secondary node(s) (or cluster members). Only after confirming replication does the system commit these events to **RocksDB** (specialized embedded event store).
   This ensures that if the primary node fails, a secondary node can continue from the last replicated point without data loss.

2. **Storage in RocksDB**  
   Persisted events are stored in RocksDB so that actors can quickly load (or reload) their historical events for rapid recovery. 
   Lightning speed real time latency (microseconds for both reads and writes) compared to accessing data over the network which would add network round trip and IO.
   RocksDB is key-value store where key is the Actor Id and values are events and snapshots (represented as events). RocksDB organizes keys in lexicographical (or byte-wise) order by default.
   The actual structure is slightly more complicated  and each row (key-value) has key which is composite of actor type, actor id and event rank (global reactor-wide counter) and value (actor change) which contains either snapshot events or al events returned by the actor's `receive` method.

3. **Publication After Replication**  
   Once replication completes, events are published to external outputs (e.g., a broker, read-model processors). This guarantees that the read side and any external subscribers see consistent, replicated dataâ€”no duplicate publications or partially committed states.

---

## 4. CQRS and Read-Side Consistency

- dedicated processing node allows for better performance as not hampered by read queries
- state updates/events published to outside world (via broker) allow real time notifications to downstream systems so they can be consumed as commands for another stage of real time processing by different domain.
- read side is represented by one of those systems like oracle data-mart or Elastic Search. They allow to build various projections and reports and aggregate data from different types of processing (reactors and other apps)
  (something that would be hard to do and resource intensive)
- so it contributes to both real time processing as well as storing audit and historical data (streaming x queries x specialized reports)


1. **Decoupled Read and Write Models**  
   - **Command/Write Side**: Actors focus on domain logic, validate commands, and emit events.  
   - **Query/Read Side**: A separate model (or multiple projections) subscribes to the event stream to build query-optimized views.

2. **Eventual Consistency**  
   The read side is eventually consistent with the latest actor state. However, replication ensures that once events are published, they are safely mirrored across the cluster, preventing stale or divergent data in the read model.

3. **High-Performance Queries**  
   Since the read model is decoupled from command logic, it can be stored in specialized databases or caches to handle large query loads efficiently. It also allows "streaming" realtime updates to downstream systems.

---

## 5. High Availability (HA)

1. **Primary-Secondary Setup**  
   By replicating events to a secondary node before storing and publishing them, the system maintains a hot standby. In case of a primary node failure, the secondary can become the new primary, having already received all events.
   This would not be true in certain scenarios, like replication failure or replication downgrading to async. However because of ACID transactional properties of the system. The now Primary would restart processing from the last unprocessed input from its viewpoint and consistently arrive at the same state as original primary.
   Outputs would be filtered based on the already published outputs as a part of the replication-recovery algorithm.

2. **No Duplication During Failover**  
   Because replication and event publication are carefully sequenced, a failover does not result in duplicate event processing. The newly active primary continues from the last acknowledged replication point which also contains reference to last processed input.

3. **Actor Recovery**  
   Actors can be restarted on another node without losing state. Their events (already replicated) can be replayed to restore the exact in-memory state they had before on another node.

---

## 6. CLI, Rest endpoints & Metrics
System provides means to see current reactor state. This includes following capabilities:
- **Command-line interface** - can be used list different actor types, actors and their events, provides statistics and methods to query actors, delete actors and ability to read and update bookmarks/watermarks
- **Web extension** - technical view, which allows to see current actor state and also travel back in time and see the state of the actor before the events were applied, it shows basic configuration of the reactor and can display system audit events and more....
- **Metrics and grafana** - all the metrics are published to influxdb and there are default dashboards that show Host, JVM and reactor metrics all together making it easy to relate the metrics to each other 
